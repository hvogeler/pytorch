{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, dataloader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch.onnx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET_NAME = 'data/landing_club/accepted_2007_to_2018Q4.csv'\n",
    "SMALL_SAMPLE_DATASET_NAME = 'data/landing_club/accepted_2007_to_2018Q4_small_sample.csv'\n",
    "SMALL_HEAD_DATASET_NAME = 'data/landing_club/accepted_2007_to_2018Q4_small_head.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample a few records for faster work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make small dataset\n",
    "# col_names = ['loan_amnt', 'home_ownership', 'annual_inc', 'purpose', 'addr_state', 'term', 'emp_length', 'int_rate']\n",
    "# col_names = ['loan_amnt', 'home_ownership', 'annual_inc','term', 'emp_length', 'int_rate']\n",
    "col_names = ['loan_amnt', 'home_ownership', 'annual_inc', 'int_rate']\n",
    "record_count = 1000\n",
    "# acc_raw_df = pd.read_csv(FULL_DATASET_NAME)\n",
    "# acc_raw_df.sample(record_count).to_csv(SMALL_SAMPLE_DATASET_NAME, columns=col_names)\n",
    "# acc_raw_df.head(record_count).to_csv(SMALL_HEAD_DATASET_NAME, columns=col_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Landing_Club_Dataset(Dataset):\n",
    "    def __init__(self, file_path: str, col_label: str, col_names = []):\n",
    "        self.file_path = file_path\n",
    "        self.df = pd.read_csv(file_path, usecols = col_names)\n",
    "        self.df.describe()\n",
    "        self.np = self.to_numpy()\n",
    "        self.col_label = col_label\n",
    "        self.clean()\n",
    "        self.encode_categorical_columns()\n",
    "        self.to_tensor()\n",
    "    \n",
    "    def __get_item__(self, index: int):\n",
    "        return (self.X_tsor[index], self.y_tsor[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def to_numpy(self):\n",
    "        return self.df.to_numpy()\n",
    "    \n",
    "    def to_tensor(self, with_grad=False):\n",
    "        # return torch.from_numpy(self.np.astype(np.float32))\n",
    "        self._split_X_y()\n",
    "        self.X_tsor = torch.tensor(self.X_df.values, requires_grad=with_grad)\n",
    "        self.y_tsor = torch.tensor(self.y_df.values, requires_grad=with_grad)\n",
    "    \n",
    "    def clean(self):\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.np = self.to_numpy()\n",
    "        return\n",
    "    \n",
    "    def encode_categorical_columns(self):\n",
    "        categorical_cols = list(self.df.select_dtypes(include=['object']))\n",
    "        print(categorical_cols)\n",
    "        label_enc = LabelEncoder()\n",
    "        for col in categorical_cols:\n",
    "            label_encoded = label_enc.fit_transform(self.df[col])\n",
    "            self.df[col] = label_encoded\n",
    "        self.np = self.to_numpy()\n",
    "        print(self.np)\n",
    "\n",
    "    def _split_X_y(self):\n",
    "        self.X_df = self.df.drop(columns=['int_rate'])\n",
    "        self.y_df = self.df['int_rate']\n",
    "\n",
    "    def _split_train_test_and_standardize(self, test_size):\n",
    "        X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(self.X_df.values, self.y_df.values, test_size=test_size)\n",
    "\n",
    "        self.sc_x = StandardScaler()\n",
    "        self.sc_y = StandardScaler()\n",
    "\n",
    "        y_train_orig = y_train_orig.reshape(-1, 1)\n",
    "        y_test_orig = y_test_orig.reshape(-1, 1)\n",
    "        self.X_train = self.sc_x.fit_transform(X_train_orig)\n",
    "        self.X_test = self.sc_x.transform(X_test_orig)\n",
    "        self.y_train = self.sc_y.fit_transform(y_train_orig)\n",
    "        self.y_test = self.sc_y.transform(y_test_orig)\n",
    "    \n",
    "    def get_train_dataset(self):\n",
    "        if (not hasattr(self, 'X_train')):\n",
    "            self._split_train_test_and_standardize(test_size=.2)\n",
    "        X_train_tsor = torch.from_numpy(self.X_train.astype(np.float32))\n",
    "        y_train_tsor = torch.from_numpy(self.y_train.astype(np.float32))\n",
    "        return (X_train_tsor, y_train_tsor)\n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        if (not hasattr(self, 'X_train')):\n",
    "            self._split_train_test_and_standardize(test_size=.2)\n",
    "        X_test_tsor = torch.from_numpy(self.X_test.astype(np.float32))\n",
    "        y_test_tsor = torch.from_numpy(self.y_test.astype(np.float32))\n",
    "        return (X_test_tsor, y_test_tsor)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Nan rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove records with nan\n",
    "# acc_df = acc_raw_df.loc[:, col_names]\n",
    "# acc_df_len = len(acc_df)\n",
    "\n",
    "# acc_df.dropna(inplace=True)\n",
    "# print(f'Records dropped: {acc_df_len - len(acc_df)}')\n",
    "\n",
    "# print(acc_df.head(10))\n",
    "# acc_df.describe()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding functions for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_one_hot(df):\n",
    "#    categorical_cols = list(acc_df.select_dtypes(include=['object']))\n",
    "#    print(categorical_cols)\n",
    "#    one_hot_enc = OneHotEncoder(sparse_output=False)\n",
    "#    for col in categorical_cols:\n",
    "#       label_encoded = one_hot_enc.fit_transform(df[col].to_numpy().reshape(-1, 1))\n",
    "#       print(col)\n",
    "#       df[col] = label_encoded.tolist()\n",
    "#    return df\n",
    "\n",
    "# def encode_label(df):\n",
    "#    categorical_cols = list(acc_df.select_dtypes(include=['object']))\n",
    "#    print(categorical_cols)\n",
    "#    label_enc = LabelEncoder()\n",
    "#    for col in categorical_cols:\n",
    "#       label_encoded = label_enc.fit_transform(df[col])\n",
    "#       df[col] = label_encoded\n",
    "#    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Landing_Club_Dataset(SMALL_HEAD_DATASET_NAME, ['int_rate'], col_names)\n",
    "\n",
    "dataset.df.head(9)\n",
    "type(dataset.df.int_rate[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model explicitely as a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_count = len(dataset.X_df.columns)\n",
    "\n",
    "class ClassModel(nn.Module):\n",
    "   def __init__(self, input_dim, output_dim):\n",
    "      super().__init__()\n",
    "      self.fc1 = nn.Linear(input_dim, 5)\n",
    "      self.relu1 = nn.ReLU()\n",
    "      self.fc2 = nn.Linear(5, 5)\n",
    "      self.relu2 = nn.ReLU()\n",
    "      self.fc3 = nn.Linear(5, 1)\n",
    "\n",
    "   def forward(self, X):\n",
    "      x = self.fc1(X)\n",
    "      x = self.relu1(x)\n",
    "      x = self.fc2(x)\n",
    "      x = self.relu2(x)\n",
    "      x = self.fc3(x)\n",
    "      return x\n",
    "   \n",
    "class_model = ClassModel(feature_count, 1)\n",
    "seq_model = nn.Sequential(\n",
    "   nn.Linear(feature_count, 15),\n",
    "   nn.Sigmoid(),\n",
    "   nn.Linear(15, 15),\n",
    "   nn.Sigmoid(),\n",
    "   nn.Linear(15, 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(lr=.3, params=seq_model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_tsor, y_train_tsor) = dataset.get_train_dataset()\n",
    "(X_test_tsor, y_test_tsor) = dataset.get_test_dataset()\n",
    "\n",
    "print(X_train_tsor[0:9])\n",
    "print(y_train_tsor[0:9])\n",
    "# print(f'Encode {y_train_orig[5][0]} = {y_train[5][0]}, Decode = {sc_y.inverse_transform(y_train[5][0].reshape(-1, 1)).reshape(1)[0]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "n_epochs = 20000\n",
    "seq_model.train()\n",
    "for n in range(n_epochs):\n",
    "   # outputs = myModel(X_train_tsor)\n",
    "   outputs = seq_model(X_train_tsor)\n",
    "   \n",
    "   loss = criterion(outputs, y_train_tsor)\n",
    "   losses.append(loss)\n",
    "   # print(loss.item())\n",
    "   if (n % (n_epochs / 10) == 0):\n",
    "      with torch.no_grad():\n",
    "         peek_output_element = 3\n",
    "         print(f'Loss on epoch ' \n",
    "               f'{n:04}: {loss.item():.4f} - '\n",
    "               f'interest rate: '\n",
    "               f'{dataset.sc_y.inverse_transform(outputs[peek_output_element].reshape(-1,1)).reshape(1).item():.4f}'\n",
    "               f'/ '\n",
    "               f'{dataset.sc_y.inverse_transform(y_train_tsor[peek_output_element].reshape(-1, 1)).reshape(1).item():.4f}')\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "   optimizer.zero_grad()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "   seq_model.eval()\n",
    "   preds = seq_model(X_test_tsor)\n",
    "   # X_test_feat_0 = X_test[2:, 0:1].reshape(-1)\n",
    "   preds_decoded = dataset.sc_y.inverse_transform(preds)\n",
    "   y_test_tsor_decoded = dataset.sc_y.inverse_transform(y_test_tsor)\n",
    "   for i in range(0, 10):\n",
    "      print(f'Prediction / Test [{i}] = '\n",
    "            f'{preds_decoded[i].reshape(-1, 1)} / '\n",
    "            f'{y_test_tsor_decoded[i].reshape(-1, 1)}')\n",
    "   plt.cla()\n",
    "   plt.plot(preds_decoded)\n",
    "   plt.plot(y_test_tsor_decoded)\n",
    "   # plt.scatter(X_test_feat_0[0:10], y_test[0:10])\n",
    "   # plt.scatter(X_test_feat_0[0:10], preds[0:10])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
